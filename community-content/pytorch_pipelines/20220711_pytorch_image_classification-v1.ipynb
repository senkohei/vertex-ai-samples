{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d69c72-3704-4bfb-8129-4eb6b0bf6808",
   "metadata": {},
   "source": [
    "### ref https://github.com/amygdala/code-snippets/blob/master/ml/vertex_pipelines/pytorch/cifar/pytorch_cifar10_vertex_pipelines.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1845b63b-3a83-4826-b441-9e89454b5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = '--user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab5715b-d9ae-4e24-ba4b-6bde52a431eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.7/site-packages (1.13.0)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.15.0-py2.py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.8.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.34.3)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.20.4)\n",
      "Requirement already satisfied: protobuf<4.0.0dev,>=3.19.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (3.20.1)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.6.6)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.56.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.46.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.46.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (4.8)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (1.26.9)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.21)\n",
      "Installing collected packages: google-cloud-aiplatform\n",
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.15.0\n",
      "Collecting kfp\n",
      "  Downloading kfp-1.8.12.tar.gz (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py<2,>=0.9\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML<6,>=5.3\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.8.0)\n",
      "Collecting google-cloud-storage<2,>=1.20.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes<19,>=8.0.0\n",
      "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-python-client<2,>=1.7.8\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.1\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.1.0)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.2.tar.gz (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.1.3)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.14.1-py3-none-any.whl (33 kB)\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.14\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.20.1)\n",
      "Collecting uritemplate<4,>=3.0.1\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.9.1)\n",
      "Collecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting typing-extensions<4,>=3.7.4\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.11.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.14.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.56.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (59.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.9)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2022.5.18.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (2.21)\n",
      "Building wheels for collected packages: kfp, fire, kfp-server-api, strip-hints, termcolor\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.12-py3-none-any.whl size=419048 sha256=fa6f9f2e95bf7aa1417759166d3d812f58cb7ca02b50d0a6508973c95f6415f3\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/54/0c/4a/3fc55077bc88cc17eacaae34c5fd3f6178c1d16d2ee3b0afdf\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=e919b86713fdc7358ef94acc8cb509d0011d12eca8e9c5dcf97be38b302225b3\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.2-py3-none-any.whl size=99716 sha256=4d25bcaeb66357af8554ea2d48748f58b47448ee52af3e617331911d84f2347f\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/77/36/d3/60e33cc9e15f269fe0e0f71cae6d077a5e43973d514b60b4ad\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=13ee1c8de74b41e43d3b1a5e7b2bf10b9c6dc0d6e784aa760c1411e624793087\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=2052cc7ef8200b509bd61b1a399f46d80671a06f3bc144fc2b39427927f4608b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built kfp fire kfp-server-api strip-hints termcolor\n",
      "Installing collected packages: typing-extensions, termcolor, uritemplate, tabulate, strip-hints, PyYAML, kfp-pipeline-spec, fire, docstring-parser, Deprecated, cachetools, absl-py, requests-toolbelt, kfp-server-api, jsonschema, google-auth, typer, kubernetes, google-api-python-client, google-cloud-storage, kfp\n",
      "\u001b[33m  WARNING: The script tabulate is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script strip-hints is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jsonschema is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts dsl-compile, dsl-compile-v2 and kfp are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 PyYAML-5.4.1 absl-py-1.1.0 cachetools-4.2.4 docstring-parser-0.14.1 fire-0.4.0 google-api-python-client-1.12.11 google-auth-1.35.0 google-cloud-storage-1.44.0 jsonschema-3.2.0 kfp-1.8.12 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.2 kubernetes-18.20.0 requests-toolbelt-0.9.1 strip-hints-0.1.10 tabulate-0.8.10 termcolor-1.1.0 typer-0.5.0 typing-extensions-3.10.0.2 uritemplate-3.0.1\n",
      "Collecting google_cloud_pipeline_components\n",
      "  Downloading google_cloud_pipeline_components-1.0.13-py3-none-any.whl (600 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.0/600.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kfp<2.0.0,>=1.8.9 in ./.local/lib/python3.7/site-packages (from google_cloud_pipeline_components) (1.8.12)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2,>=1.11.0 in ./.local/lib/python3.7/site-packages (from google_cloud_pipeline_components) (1.15.0)\n",
      "Collecting google-cloud-notebooks>=0.4.0\n",
      "  Downloading google_cloud_notebooks-1.4.0-py2.py3-none-any.whl (355 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.5/355.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-cloud-storage<2,>=1.20.0 in ./.local/lib/python3.7/site-packages (from google_cloud_pipeline_components) (1.44.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from google_cloud_pipeline_components) (2.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (1.56.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in ./.local/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (3.20.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (1.5.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (1.20.4)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (2.34.3)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (21.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->google_cloud_pipeline_components) (2.3.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->google_cloud_pipeline_components) (1.16.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->google_cloud_pipeline_components) (2.3.0)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (3.10.0.2)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.14.1)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (8.1.3)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (3.2.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.2.13)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (3.0.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.9.1)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.1.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.8.10)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.9.1)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (18.20.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.12.11)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.14 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.1.16)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.4.0)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (2.1.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.5.0)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.1.10)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in ./.local/lib/python3.7/site-packages (from kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (4.11.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.14.1)\n",
      "Requirement already satisfied: termcolor in ./.local/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.1.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (1.46.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (1.46.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.local/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (4.2.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (59.8.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (0.12.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->google_cloud_pipeline_components) (1.1.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (21.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.26.9)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.3.2)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform<2,>=1.11.0->google_cloud_pipeline_components) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (3.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (0.37.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->google_cloud_pipeline_components) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google_cloud_pipeline_components) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (3.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google_cloud_pipeline_components) (3.2.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->google_cloud_pipeline_components) (2.21)\n",
      "Installing collected packages: google-cloud-notebooks, google_cloud_pipeline_components\n",
      "Successfully installed google-cloud-notebooks-1.4.0 google_cloud_pipeline_components-1.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user -U google-cloud-aiplatform \n",
    "!pip3 install --user -U kfp\n",
    "!pip3 install --user -U google_cloud_pipeline_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceb4fba-d818-49cd-b0c1-b1961401d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfpを新規installした場合こちらを実行\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7facf97c-20d5-4aba-a913-fce91939d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    InputPath,\n",
    "    OutputPath,\n",
    "    Input,\n",
    "    Output,\n",
    "    Artifact,\n",
    "    Dataset,\n",
    "    Model,\n",
    "    ClassificationMetrics,\n",
    "    Metrics,\n",
    ")\n",
    "\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdecd608-6298-4bd3-a301-ad6f37539719",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'argolis-demo-project'  # <---CHANGE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551193d2-a058-45a4-8938-5af732d3002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://argolis-demo-senchan\"  # @param {type:\"string\"}\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16eae2b7-4871-4bb3-82e6-0f64c1f26cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://argolis-demo-senchan/pipeline_root/argolis-demo'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "\n",
    "USER = 'argolis-demo' # <---CHANGE THIS\n",
    "PIPELINE_ROOT = '{}/pipeline_root/{}'.format(BUCKET_NAME, USER)\n",
    "\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c44c6ce-afcd-420c-aa79-d59101c04441",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_URI = \"gcr.io/google-samples/pytorch-pl:v2\"\n",
    "GPU_CONTAINER_URI = \"gcr.io/google-samples/pytorch-pl-gpu:v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b54c725f-00af-4c81-8839-cc471754f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=\"cifar_preproc.yaml\",\n",
    ")\n",
    "def cifar_preproc(\n",
    "    cifar_dataset: Output[Dataset],\n",
    "):\n",
    "\n",
    "    import subprocess\n",
    "    import logging\n",
    "    from pathlib import Path\n",
    "\n",
    "    import torchvision\n",
    "    import webdataset as wds\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info(\"Dataset path is: %s\", cifar_dataset.path)\n",
    "    output_pth = cifar_dataset.path\n",
    "\n",
    "    Path(output_pth).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./\", train=True, download=True\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./\", train=False, download=True\n",
    "    )\n",
    "\n",
    "    Path(output_pth + \"/train\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(output_pth + \"/val\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(output_pth + \"/test\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    random_seed = 25\n",
    "    y = trainset.targets\n",
    "    trainset, valset, y_train, y_val = train_test_split(\n",
    "        trainset,\n",
    "        y,\n",
    "        stratify=y,\n",
    "        shuffle=True,\n",
    "        test_size=0.2,\n",
    "        random_state=random_seed,\n",
    "    )\n",
    "\n",
    "    for name in [(trainset, \"train\"), (valset, \"val\"), (testset, \"test\")]:\n",
    "        with wds.ShardWriter(\n",
    "            output_pth + \"/\" + str(name[1]) + \"/\" + str(name[1]) + \"-%d.tar\",\n",
    "            maxcount=1000,\n",
    "        ) as sink:\n",
    "            for index, (image, cls) in enumerate(name[0]):\n",
    "                sink.write(\n",
    "                    {\"__key__\": \"%06d\" % index, \"ppm\": image, \"cls\": cls}\n",
    "                )\n",
    "\n",
    "    entry_point = [\"ls\", \"-R\", output_pth]\n",
    "    run_code = subprocess.run(entry_point, stdout=subprocess.PIPE)\n",
    "    print(run_code.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f21d7a-f074-46c4-80c7-81d20ab793a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    output_component_file=\"cifar_config.yaml\",\n",
    ")\n",
    "def cifar_config(\n",
    "    mar_model_name: str,\n",
    "    version: str,\n",
    "    port: int,\n",
    "    cifar_config: Output[Artifact],\n",
    "):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    Path(cifar_config.path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    config_properties = f\"\"\"inference_address=http://0.0.0.0:{port}\n",
    "management_address=http://0.0.0.0:8081\n",
    "metrics_address=http://0.0.0.0:8082\n",
    "enable_metrics_api=true\n",
    "metrics_format=prometheus\n",
    "number_of_netty_threads=4\n",
    "job_queue_size=10\n",
    "service_envelope=kfserving\n",
    "model_store=/home/model-server/model-store\n",
    "model_snapshot={{\"name\":\"startup.cfg\",\"modelCount\":1,\"models\":{{\"{mar_model_name}\":{{\"{version}\":{{\"defaultVersion\":true,\"marName\":\"{mar_model_name}.mar\",\"minWorkers\":1,\"maxWorkers\":5,\"batchSize\":1,\"maxBatchDelay\":5000,\"responseTimeout\":120}}}}}}}}\n",
    "\"\"\"\n",
    "\n",
    "    # write to artifact dir\n",
    "    properties_path = os.path.join(cifar_config.path, \"config.properties\")\n",
    "    with open(properties_path, \"w\") as f:\n",
    "        f.write(config_properties)\n",
    "\n",
    "    torchserve_dockerfile_str = f\"\"\"FROM pytorch/torchserve:0.5.1-gpu\n",
    "\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install grpcio==1.32.0\n",
    "RUN pip install pytorch-lightning\n",
    "\n",
    "COPY config.properties /home/model-server/config.properties\n",
    "COPY {mar_model_name}.mar /home/model-server/model-store/\n",
    "\"\"\"\n",
    "    # write to artifact dir\n",
    "    dockerfile_path = os.path.join(cifar_config.path, \"Dockerfile\")\n",
    "    with open(dockerfile_path, \"w\") as f:\n",
    "        f.write(torchserve_dockerfile_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78eb054a-07fa-46f1-b9ee-a3464c98ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=GPU_CONTAINER_URI,\n",
    "    output_component_file=\"cifar_train.yaml\",\n",
    ")\n",
    "def cifar_train(\n",
    "    model_name: str,\n",
    "    max_epochs: int,\n",
    "    model_display_name: str,\n",
    "    tensorboard_instance:str,\n",
    "    cifar_dataset: Input[Dataset],\n",
    "    cifar_model: Output[Model],\n",
    "):\n",
    "\n",
    "    import pytorch_lightning as pl\n",
    "    import logging\n",
    "    import os\n",
    "    from subprocess import Popen, DEVNULL\n",
    "    import sys\n",
    "\n",
    "    from pytorch_pipeline.components.trainer.component import Trainer\n",
    "    from argparse import ArgumentParser\n",
    "    from pytorch_lightning.loggers import TensorBoardLogger\n",
    "    from pytorch_lightning.callbacks import (\n",
    "        EarlyStopping,\n",
    "        LearningRateMonitor,\n",
    "        ModelCheckpoint,\n",
    "    )\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info(\"datset root path: %s\", cifar_dataset.path)\n",
    "    logging.info(\"model root path: %s\", cifar_model.path)\n",
    "    model_output_root = cifar_model.path\n",
    "\n",
    "    # Argument parser for user defined paths\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--tensorboard_root\",\n",
    "        type=str,\n",
    "        default=f\"{model_output_root}/tensorboard\",\n",
    "        help=\"Tensorboard Root path (default: output/tensorboard)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint_dir\",\n",
    "        type=str,\n",
    "        default=f\"{model_output_root}/train/models\",\n",
    "        help=\"Path to save model checkpoints \",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--dataset_path\",\n",
    "        type=str,\n",
    "        default=cifar_dataset.path,\n",
    "        help=\"Cifar10 Dataset path (default: output/processing)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--model_name\",\n",
    "        type=str,\n",
    "        default=\"resnet.pth\",\n",
    "        help=\"Name of the model to be saved as (default: resnet.pth)\",\n",
    "    )\n",
    "\n",
    "    sys.argv = sys.argv[:1]\n",
    "\n",
    "    parser = pl.Trainer.add_argparse_args(parent_parser=parser)\n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    # Enabling Tensorboard Logger, ModelCheckpoint, Earlystopping\n",
    "    lr_logger = LearningRateMonitor()\n",
    "    tboard = TensorBoardLogger(f\"{model_output_root}/tensorboard\")\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", mode=\"min\", patience=5, verbose=True\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"{model_output_root}/train/models\",\n",
    "        filename=\"cifar10_{epoch:02d}\",\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    # Setting the trainer-specific arguments\n",
    "    trainer_args = {\n",
    "        \"logger\": tboard,\n",
    "        \"profiler\": \"pytorch\",\n",
    "        \"checkpoint_callback\": True,\n",
    "        \"max_epochs\": max_epochs,\n",
    "        \"callbacks\": [lr_logger, early_stopping, checkpoint_callback],\n",
    "        \"gpus\": 1,\n",
    "    }\n",
    "\n",
    "    # Setting the datamodule specific arguments\n",
    "    data_module_args = {\"train_glob\": cifar_dataset.path}\n",
    "\n",
    "    if tensorboard_instance:\n",
    "      try:\n",
    "        logging.warning('setting up Vertex tensorboard experiment')\n",
    "        tb_gs = f\"{model_output_root}/tensorboard\".replace(\"/gcs/\", \"gs://\")\n",
    "        logging.info('tb gs path: %s', tb_gs)\n",
    "        tb_args = [\"/opt/conda/bin/tb-gcp-uploader\", \"--tensorboard_resource_name\", tensorboard_instance, \n",
    "                        \"--logdir\", tb_gs, \"--experiment_name\", model_display_name,\n",
    "                        # '--one_shot=True'\n",
    "                        ]\n",
    "        logging.warning('tb args: %s', tb_args)\n",
    "        Popen(tb_args, stdout=DEVNULL, stderr=DEVNULL)\n",
    "      except Exception as e:\n",
    "        logging.warning(e)\n",
    "\n",
    "    # Initiating the training process\n",
    "    logging.info(\"about to call the Trainer...\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        module_file=\"cifar10_train.py\",\n",
    "        data_module_file=\"cifar10_datamodule.py\",\n",
    "        module_file_args=parser,\n",
    "        data_module_args=data_module_args,\n",
    "        trainer_args=trainer_args,\n",
    "    )\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6202f2-4e43-4add-afb9-818f25b5e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=CONTAINER_URI,\n",
    "    output_component_file=\"mar.yaml\",\n",
    ")\n",
    "def generate_mar_file(\n",
    "    model_name: str,\n",
    "    mar_model_name: str,\n",
    "    handler: str,\n",
    "    version: str,\n",
    "    cifar_model: Input[Model],\n",
    "    cifar_mar: Output[Model],\n",
    "):\n",
    "\n",
    "    import logging\n",
    "    import pytorch_lightning as pl\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    from pathlib import Path\n",
    "\n",
    "    def _validate_mar_config(mar_config):\n",
    "        mandatory_args = [\n",
    "            \"MODEL_NAME\",\n",
    "            \"SERIALIZED_FILE\",\n",
    "            \"MODEL_FILE\",\n",
    "            \"HANDLER\",\n",
    "            \"VERSION\",\n",
    "        ]\n",
    "        missing_list = []\n",
    "        for key in mandatory_args:\n",
    "            if key not in mar_config:\n",
    "                missing_list.append(key)\n",
    "\n",
    "        if missing_list:\n",
    "            logging.warning(\n",
    "                \"The following Mandatory keys are missing in the config file {} \".format(\n",
    "                    missing_list\n",
    "                )\n",
    "            )\n",
    "            raise Exception(\n",
    "                \"Following Mandatory keys are missing in the config file {} \".format(\n",
    "                    missing_list\n",
    "                )\n",
    "            )\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    model_output_root = cifar_model.path\n",
    "    mar_output_root = cifar_mar.path\n",
    "    export_path = f\"{mar_output_root}/model-store\"\n",
    "    try:\n",
    "        Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        logging.warning(e)\n",
    "        # retry after pause\n",
    "        import time\n",
    "\n",
    "        time.sleep(2)\n",
    "        Path(export_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    mar_config = {\n",
    "        \"MODEL_NAME\": mar_model_name,\n",
    "        \"MODEL_FILE\": \"pytorch_pipeline/examples/cifar10/cifar10_train.py\",\n",
    "        \"HANDLER\": handler,\n",
    "        \"SERIALIZED_FILE\": os.path.join(\n",
    "            f\"{model_output_root}/train/models\",\n",
    "            model_name,\n",
    "        ),\n",
    "        \"VERSION\": version,\n",
    "        \"EXPORT_PATH\": f\"{cifar_mar.path}/model-store\",\n",
    "    }\n",
    "    logging.warning(\"mar_config: %s\", mar_config)\n",
    "    print(f\"mar_config: {mar_config}\")\n",
    "    try:\n",
    "        logging.info(\"validating config\")\n",
    "        _validate_mar_config(mar_config)\n",
    "    except Exception as e:\n",
    "        logging.warning(e)\n",
    "\n",
    "    archiver_cmd = \"torch-model-archiver --force --model-name {MODEL_NAME} --serialized-file {SERIALIZED_FILE} --model-file {MODEL_FILE} --handler {HANDLER} -v {VERSION}\".format(\n",
    "        MODEL_NAME=mar_config[\"MODEL_NAME\"],\n",
    "        SERIALIZED_FILE=mar_config[\"SERIALIZED_FILE\"],\n",
    "        MODEL_FILE=mar_config[\"MODEL_FILE\"],\n",
    "        HANDLER=mar_config[\"HANDLER\"],\n",
    "        VERSION=mar_config[\"VERSION\"],\n",
    "    )\n",
    "    if \"EXPORT_PATH\" in mar_config:\n",
    "        archiver_cmd += \" --export-path {EXPORT_PATH}\".format(\n",
    "            EXPORT_PATH=mar_config[\"EXPORT_PATH\"]\n",
    "        )\n",
    "\n",
    "    if \"EXTRA_FILES\" in mar_config:\n",
    "        archiver_cmd += \" --extra_files {EXTRA_FILES}\".format(\n",
    "            EXTRA_FILES=mar_config[\"EXTRA_FILES\"]\n",
    "        )\n",
    "\n",
    "    if \"REQUIREMENTS_FILE\" in mar_config:\n",
    "        archiver_cmd += \" -r {REQUIREMENTS_FILE}\".format(\n",
    "            REQUIREMENTS_FILE=mar_config[\"REQUIREMENTS_FILE\"]\n",
    "        )\n",
    "\n",
    "    print(\"Running Archiver cmd: \", archiver_cmd)\n",
    "    logging.warning(\"archiver command: %s\", archiver_cmd)\n",
    "\n",
    "    try:\n",
    "        return_code = subprocess.Popen(archiver_cmd, shell=True).wait()\n",
    "        if return_code != 0:\n",
    "            error_msg = (\n",
    "                \"Error running command {archiver_cmd} {return_code}\".format(\n",
    "                    archiver_cmd=archiver_cmd, return_code=return_code\n",
    "                )\n",
    "            )\n",
    "            print(error_msg)\n",
    "    except Exception as e:\n",
    "        logging.warning(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d29753f-be8f-4c2f-be83-d6df791c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.duration_pb2 import Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c98954be-8fe4-4eda-bf65-22489241b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-3:latest\",\n",
    "    output_component_file=\"build_image.yaml\",\n",
    ")\n",
    "def build_torchserve_image(\n",
    "    model_name: str,\n",
    "    cifar_mar: Input[Model],\n",
    "    cifar_config: Input[Artifact],\n",
    "    project: str,\n",
    ") -> NamedTuple(\"Outputs\", [(\"serving_container_uri\", str),],):\n",
    "\n",
    "    from datetime import datetime\n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    import google.auth\n",
    "    from google.cloud.devtools import cloudbuild_v1\n",
    "    from google.protobuf.duration_pb2 import Duration\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    credentials, project_id = google.auth.default()\n",
    "    client = cloudbuild_v1.services.cloud_build.CloudBuildClient()\n",
    "\n",
    "    mar_model_name = f\"{model_name}.mar\"\n",
    "    build_version = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    dockerfile_path = os.path.join(cifar_config.path, \"Dockerfile\")\n",
    "    gs_dockerfile_path = dockerfile_path.replace(\"/gcs/\", \"gs://\")\n",
    "    config_prop_path = os.path.join(cifar_config.path, \"config.properties\")\n",
    "    gs_config_prop_path = config_prop_path.replace(\"/gcs/\", \"gs://\")\n",
    "\n",
    "    export_path = f\"{cifar_mar.path}/model-store\"\n",
    "    model_path = os.path.join(export_path, mar_model_name)\n",
    "    gs_model_path = model_path.replace(\"/gcs/\", \"gs://\")\n",
    "    logging.warning(\"gs_model_path: %s\", gs_model_path)\n",
    "\n",
    "    image_uri = f\"gcr.io/{project}/torchservetest:{build_version}\"\n",
    "    logging.info(\"image uri: %s\", image_uri)\n",
    "\n",
    "    build = cloudbuild_v1.Build(images=[image_uri])\n",
    "    build.steps = [\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\n",
    "                \"cp\",\n",
    "                gs_config_prop_path,\n",
    "                \"config.properties\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\"cp\", f\"{gs_model_path}\", f\"{mar_model_name}\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\n",
    "                \"cp\",\n",
    "                gs_dockerfile_path,\n",
    "                \"Dockerfile\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "            \"args\": [\"build\", \"-t\", image_uri, \".\"],\n",
    "        },\n",
    "    ]\n",
    "    timeout = Duration()\n",
    "    timeout.seconds = 7200\n",
    "    build.timeout = timeout\n",
    "    \n",
    "    operation = client.create_build(project_id=project, build=build)\n",
    "    print(\"IN PROGRESS:\")\n",
    "    print(operation.metadata)\n",
    "\n",
    "    result = operation.result()\n",
    "    # Print the completed status\n",
    "    print(\"RESULT:\", result.status)\n",
    "    return (image_uri,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62be5eae-5c6e-4d06-a7fc-dac55961271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "MODEL_NAME = f'resnet{ts}'\n",
    "PORT = 8080\n",
    "MAR_MODEL_NAME = 'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ffd45de-ba5e-430a-962b-759db2ea1aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8080\n"
     ]
    }
   ],
   "source": [
    "print(PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "456805ce-d6e5-4a49-abce-aecf51706a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet20220714090809\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a87da0d2-9990-4f5f-9255-ae3c6c63bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"pytorch-cifar-pipeline\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def pytorch_cifar_pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    model_name: str = \"resnet.pth\",\n",
    "    model_display_name: str = MODEL_NAME,\n",
    "    max_epochs: int = 1,\n",
    "    mar_model_name: str = MAR_MODEL_NAME,\n",
    "    handler: str = \"image_classifier\",\n",
    "    version: str = \"1.0\",\n",
    "    port: int = PORT,\n",
    "    tensorboard_instance: str = ''\n",
    "):\n",
    "\n",
    "    cifar_config_task = cifar_config(mar_model_name, version, port)\n",
    "    cifar_preproc_task = cifar_preproc()\n",
    "\n",
    "    cifar_train_task = cifar_train(\n",
    "        model_name=model_name,\n",
    "        max_epochs=max_epochs,\n",
    "        model_display_name=model_display_name,\n",
    "        tensorboard_instance=tensorboard_instance,\n",
    "        cifar_dataset=cifar_preproc_task.outputs[\"cifar_dataset\"],\n",
    "    ).set_memory_limit('32G').set_gpu_limit(1)\n",
    "    cifar_train_task.add_node_selector_constraint(\n",
    "        # You can change this to use a different accelerator. Ensure you have quota for it.\n",
    "        \"cloud.google.com/gke-accelerator\", \"nvidia-tesla-v100\"\n",
    "    )\n",
    "\n",
    "    cifar_mar_task = generate_mar_file(\n",
    "        model_name,\n",
    "        mar_model_name,\n",
    "        handler,\n",
    "        version,\n",
    "        cifar_train_task.outputs[\"cifar_model\"],\n",
    "    )\n",
    "\n",
    "    build_image_task = build_torchserve_image(\n",
    "        mar_model_name, cifar_mar_task.outputs[\"cifar_mar\"], \n",
    "        cifar_config_task.outputs['cifar_config'],\n",
    "        project\n",
    "    )\n",
    "\n",
    "    #gcc_aip.ModelUploadOp.component_spec.implementation.container.image = \"gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7\"\n",
    "    gcc_aip.ModelUploadOp.component_spec.implementation.container.image = \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.13\"\n",
    "    model_upload_op = gcc_aip.ModelUploadOp(\n",
    "        project=project,\n",
    "        display_name=model_display_name,\n",
    "        serving_container_image_uri=build_image_task.outputs['serving_container_uri'],\n",
    "        serving_container_predict_route=\"/predictions/{}\".format(MAR_MODEL_NAME),\n",
    "        serving_container_health_route=\"/ping\",\n",
    "        #serving_container_ports=[PORT]\n",
    "        serving_container_ports=[{\"containerPort\" : PORT}]\n",
    "    )\n",
    "    \n",
    "    #gcc_aip.EndpointCreateOp.component_spec.implementation.container.image = \"gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7\"\n",
    "    gcc_aip.EndpointCreateOp.component_spec.implementation.container.image = \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.13\"\n",
    "    endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "        project=project,\n",
    "        display_name=model_display_name,\n",
    "    )\n",
    "\n",
    "    #gcc_aip.ModelDeployOp.component_spec.implementation.container.image = \"gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7\"\n",
    "    gcc_aip.ModelDeployOp.component_spec.implementation.container.image = \"gcr.io/ml-pipeline/google-cloud-pipeline-components:1.0.13\"\n",
    "    model_deploy_op = gcc_aip.ModelDeployOp(\n",
    "        #project=project,\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        model=model_upload_op.outputs[\"model\"],\n",
    "        deployed_model_display_name=model_display_name,\n",
    "        #dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "        dedicated_resources_machine_type=\"n1-standard-32\",\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        #dedicated_resources_accelerator_type='NVIDIA_TESLA_P100',  # CHANGE THIS as necessary\n",
    "        #dedicated_resources_accelerator_count=1,\n",
    "        traffic_split = {\"0\": 100}\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e4336a-d9cb-48e4-a944-f0d17c656773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import compiler as v2compiler\n",
    "v2compiler.Compiler().compile(pipeline_func=pytorch_cifar_pipeline,\n",
    "                              package_path='pytorch_pipeline_spec.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "394cd169-3b10-4014-8ab0-bc591728efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/pytorch-cifar-pipeline-20220715023900?project=278305018396\n",
      "PipelineJob projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/278305018396/locations/us-central1/pipelineJobs/pytorch-cifar-pipeline-20220715023900\n"
     ]
    }
   ],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=MODEL_NAME,\n",
    "    template_path=\"pytorch_pipeline_spec.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"model_name\": \"resnet.pth\", \"max_epochs\": 5,\n",
    "        \"project\": PROJECT_ID, \"model_display_name\": MODEL_NAME,\n",
    "        # \"tensorboard_instance\": TENSORBOARD_INSTANCE\n",
    "    },\n",
    ")\n",
    "\n",
    "job.run(sync=False\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c06a070a-dc7f-4504-9c6e-683e023e072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_ID = '73139513479659520'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b57bd-d719-47d8-a48d-50e7142bd4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify a region:\n",
      " [1] asia-east1\n",
      " [2] asia-east2\n",
      " [3] asia-northeast1\n",
      " [4] asia-northeast3\n",
      " [5] asia-south1\n",
      " [6] asia-southeast1\n",
      " [7] australia-southeast1\n",
      " [8] europe-west1\n",
      " [9] europe-west2\n",
      " [10] europe-west3\n",
      " [11] europe-west4\n",
      " [12] europe-west6\n",
      " [13] northamerica-northeast1\n",
      " [14] northamerica-northeast2\n",
      " [15] southamerica-east1\n",
      " [16] us-central1\n",
      " [17] us-east1\n",
      " [18] us-east4\n",
      " [19] us-west1\n",
      " [20] us-west2\n",
      " [21] us-west4\n",
      " [22] cancel\n",
      "Please enter your numeric choice:  "
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints predict {ENDPOINT_ID} --json-request=input.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
