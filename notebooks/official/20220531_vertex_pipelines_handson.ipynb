{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d65fa7-1c6e-4d08-b1d4-49c9686ea79b",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines Tutorial Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2434e-8fa5-456d-b3d4-59aaa0cec933",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8b48f-331f-4c9e-8936-e59ff80434cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user -U google-cloud-aiplatform \n",
    "!pip3 install --user -U kfp\n",
    "!pip3 install --user -U google_cloud_pipeline_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6260bc9-d858-46e9-98d2-53617c665fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfpを新規installした場合こちらを実行\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a2b4e-9ec6-413d-961e-69ce8cdb63e1",
   "metadata": {},
   "source": [
    "# Vertex AI Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13c541-686b-4a3d-9ee5-a8f6cda4f029",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81ffe5-9b7a-4bdd-a3f6-f598de24b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfpを新規installした場合こちらを実行\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f811f-1a4b-46ce-933f-c9ef983d77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        pipeline,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "# We'll use this namespace for metadata querying\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a552e-1037-4b1f-9d87-45f40b4af931",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65238a04-2050-4ce3-baf8-7c97a0e1da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"vertex-pipelines-handson\"\n",
    "REGION = \"us-central1\"  # @param {type: \"string\"}\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET_NAME = \"{}-pipelines\".format(PROJECT_ID)\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}/pipeline_root/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc03a9-8b40-40d2-b90e-3add8a7aa4b7",
   "metadata": {},
   "source": [
    "## Data preparation in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4884b8b-3322-42a3-8e38-5cb8985c9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQueryにDatasetを作成\n",
    "client = bigquery.Client()\n",
    "\n",
    "dataset = bigquery.Dataset(\"{}.vertexai_handson\".format(PROJECT_ID))\n",
    "dataset.location = \"US\"\n",
    "\n",
    "dataset = client.create_dataset(dataset, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65900fa0-4829-40bf-963d-fcfb0c2475a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQueryにデータを投入\n",
    "client = bigquery.Client()\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True, source_format=bigquery.SourceFormat.CSV\n",
    ")\n",
    "uri = \"gs://bigquery-handson/titanic/titanic.csv\"\n",
    "table_id = \"{}.vertexai_handson.titanic\".format(PROJECT_ID)\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "destination_table = client.get_table(table_id)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6661d-3243-42de-ac02-5023a85d0c5a",
   "metadata": {},
   "source": [
    "## Create Google Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06afe8-46be-4acc-816e-32ba0288e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client(\n",
    "#    credentials=credentials,\n",
    "    project=PROJECT_ID\n",
    ")\n",
    "\n",
    "bucket = client.create_bucket(BUCKET_NAME)\n",
    "bucket.iam_configuration.uniform_bucket_level_access_enabled = True\n",
    "bucket.patch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d536d90-3cf6-4217-8ca2-b69392a141af",
   "metadata": {},
   "source": [
    "## Define Machine Learning model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5e092-a69c-4b7c-ae12-540273a0c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"db-dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"create_dataset.yaml\"\n",
    ")\n",
    "def get_dataframe(\n",
    "    bq_table: str,\n",
    "    project: str,\n",
    "    output_data_path: OutputPath(\"Dataset\")\n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "\n",
    "    bqclient = bigquery.Client(project=project)\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe = dataframe.sample(frac=1, random_state=2)\n",
    "    dataframe.to_csv(output_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b26931-e0f4-465b-b71e-2fbd1f655d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"joblib\", \"db-dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"titanic_model_component.yaml\",\n",
    ")\n",
    "def sklearn_train(\n",
    "    dataset: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model]\n",
    "):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(dataset.path)\n",
    "    df = df.drop([\"name\",\"ticket\",\"cabin\",\"boat\",\"body\",\"home_dest\"], axis=1)\n",
    "    df[\"sex\"] = df[\"sex\"].map({\"male\":0,\"female\":1})\n",
    "    df = df[df.fare != '?']\n",
    "    df = df[df.embarked != '?']\n",
    "    df = df[df.age != '?']\n",
    "    df = pd.get_dummies(df, columns=['embarked'])\n",
    "    labels = df.pop(\"survived\").tolist()\n",
    "    data = df.values.tolist()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "    skmodel = DecisionTreeClassifier()\n",
    "    skmodel.fit(x_train,y_train)\n",
    "    score = skmodel.score(x_test,y_test)\n",
    "    print('accuracy is:',score)\n",
    "\n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    metrics.log_metric(\"framework\", \"Scikit Learn\")\n",
    "    metrics.log_metric(\"dataset_size\", len(df))\n",
    "    dump(skmodel, model.path + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8d704-8665-4125-b883-92696e6a61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"titanic_deploy_component.yaml\",\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"titanic-model-pipeline\",\n",
    "        artifact_uri = model.uri.replace(\"model\", \"\"),\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947ddd3-72f9-43dd-a1e6-638d1e25163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline.\n",
    "    name=\"titanic-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    bq_table: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    dataset_task = get_dataframe(bq_table, project)\n",
    "\n",
    "    model_task = sklearn_train(\n",
    "        dataset_task.output\n",
    "    )\n",
    "\n",
    "    deploy_task = deploy_model(\n",
    "        model=model_task.outputs[\"model\"],\n",
    "        project=project,\n",
    "        region=region\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bf023-b67b-4103-8e44-1cec1c9ae46a",
   "metadata": {},
   "source": [
    "## Complie the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edc39e-22a8-4dc2-9217-d8637012bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"titanic_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01a7c1-e6e9-4d0d-8450-e0721fabf2a8",
   "metadata": {},
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd52ae-19b6-486c-8648-60257df33311",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_run = aiplatform.PipelineJob(\n",
    "    display_name=\"titanic-pipeline\",\n",
    "    template_path=\"titanic_pipeline.json\",\n",
    "    job_id=\"titanic-pipeline-{0}\".format(TIMESTAMP),\n",
    "    parameter_values={\"bq_table\": \"{}.vertexai_handson.titanic\".format(PROJECT_ID)},\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d36b33-227c-433f-a5b9-9fde12b55a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_run.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f72c4-6a72-4ff5-abe4-1d2ca937ae41",
   "metadata": {},
   "source": [
    "## Call test for the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885665a8-d460-4b72-a71b-e12c6ae26dfe",
   "metadata": {},
   "source": [
    "### Public endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e785fea-05e7-4640-9294-0f9fda5107a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME=\"titanic-model-pipeline_endpoint\"\n",
    "instance = [[3,0,18,0,0,8.6625,0,0,1]]\n",
    "ENDPOINT_ID = !(gcloud ai endpoints list --region=$REGION \\\n",
    "              --format='value(ENDPOINT_ID)' \\\n",
    "              --filter=display_name=$ENDPOINT_NAME \\\n",
    "              --sort-by=creationTimeStamp | tail -1)\n",
    "ENDPOINT_ID = ENDPOINT_ID[1]\n",
    "print(ENDPOINT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bf7c0-377a-4e61-82cb-57d12f90c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoint_predict(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aiplatform.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    return prediction\n",
    "\n",
    "endpoint_predict(PROJECT_ID, REGION, instance, ENDPOINT_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
