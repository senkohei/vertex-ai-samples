{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0b4f2bf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5c0d0bbf74d",
    "tags": []
   },
   "source": [
    "# Vertex AI Pipelines: Custom training with pre-built Google Cloud Pipeline Components\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/pipelines/custom_model_training_and_batch_prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/pipelines/custom_model_training_and_batch_prediction.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/notebooks/deploy-notebook?download_url=https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/pipelines/custom_model_training_and_batch_prediction.ipynb\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d79790f56d30"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "This tutorial demonstrates how to use Vertex AI Pipelines with pre-built Google Cloud Pipeline Components for custom training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57139e75264f"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the [CIFAR10 dataset](https://www.tensorflow.org/datasets/catalog/cifar10) from [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/overview). The version of the dataset you will use is built into TensorFlow. The trained model predicts which type of class an image is from ten classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, or truck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b87eb4840013"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you create a custom image classification model using Vertex AI Pipelines with pre-built Google Cloud Pipeline Components for custom training.\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Train a custom model.\n",
    "- Upload the trained model as a `Model` resource.\n",
    "- Create an `Endpoint` resource.\n",
    "- Deploy the `Model` resource to the `Endpoint` resource.\n",
    "\n",
    "Learn more about [Google Cloud Pipeline Components](https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "181d4dfbf917"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_local",
    "tags": []
   },
   "source": [
    "### Set up your local development environment\n",
    "\n",
    "If you are using Colab or Google Cloud Notebook, your environment already meets all the requirements to run this notebook. You can skip this step.\n",
    "\n",
    "Otherwise, make sure your environment meets this notebook's requirements. You need the following:\n",
    "\n",
    "- The Cloud Storage SDK\n",
    "- Git\n",
    "- Python 3\n",
    "- virtualenv\n",
    "- Jupyter notebook running in a virtual environment with Python 3\n",
    "\n",
    "The Cloud Storage guide to [Setting up a Python development environment](https://cloud.google.com/python/setup) and the [Jupyter installation guide](https://jupyter.org/install) provide detailed instructions for meeting these requirements. The following steps provide a condensed set of instructions:\n",
    "\n",
    "1. [Install and initialize the SDK](https://cloud.google.com/sdk/docs/).\n",
    "\n",
    "2. [Install Python 3](https://cloud.google.com/python/setup#installing_python).\n",
    "\n",
    "3. [Install virtualenv](Ihttps://cloud.google.com/python/setup#installing_and_using_virtualenv) and create a virtual environment that uses Python 3.\n",
    "\n",
    "4. Activate that environment and run `pip3 install Jupyter` in a terminal shell to install Jupyter.\n",
    "\n",
    "5. Run `jupyter notebook` on the command line in a terminal shell to launch Jupyter.\n",
    "\n",
    "6. Open this notebook in the Jupyter Notebook Dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the latest version of Vertex AI SDK for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = '--user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --force-reinstall $USER_FLAG tensorflow==2.5 kfp google-cloud-aiplatform google-cloud-storage google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "restart"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "Once you've installed the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "before_you_begin:nogpu"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "\n",
    "2. [Make sure that billing is enabled for your project.](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "\n",
    "3. [Enable the Vertex AI APIs, Compute Engine APIs, and Cloud Storage.](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component,storage-component.googleapis.com)\n",
    "\n",
    "4. [The Google Cloud SDK](https://cloud.google.com/sdk) is already installed in Google Cloud Notebook.\n",
    "\n",
    "5. Enter your project ID in the cell below. Then run the  cell to make sure the\n",
    "Cloud SDK uses the right project for all the commands in this notebook.\n",
    "\n",
    "**Note**: Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_project_id"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"handson-test-02\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook.  Below are regions supported for Vertex AI. We recommend that you choose the region closest to you.\n",
    "\n",
    "- Americas: `us-central1`\n",
    "- Europe: `europe-west4`\n",
    "- Asia Pacific: `asia-east1`\n",
    "\n",
    "You may not use a multi-regional bucket for training with Vertex AI. Not all regions provide support for all Vertex AI services.\n",
    "\n",
    "Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "timestamp"
   },
   "source": [
    "#### Timestamp\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, create a timestamp for each instance session, and append the timestamp onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJjft8z1IA81"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "When you initialize the Vertex AI SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_URI = 'gs://handson-test-bucket' # type your bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = storage.Client(\n",
    "#    credentials=credentials,\n",
    "    project=PROJECT_ID\n",
    ")\n",
    "\n",
    "bucket = client.create_bucket(BUCKET_URI)\n",
    "bucket.iam_configuration.uniform_bucket_level_access_enabled = True\n",
    "bucket.patch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "Next, set up some variables used throughout the tutorial.\n",
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "import tensorflow as tf\n",
    "from google_cloud_pipeline_components.experimental.custom_job import utils\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline_constants"
   },
   "source": [
    "#### Vertex AI Pipelines constants\n",
    "\n",
    "Setup up the following constants for Vertex AI Pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline_constants"
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/tf_cifar\".format(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "## Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yX-aimhGRRRl"
   },
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "accelerators:training,cpu,prediction,cpu,mbsdk"
   },
   "source": [
    "#### Set hardware accelerators\n",
    "\n",
    "You can set hardware accelerators for training and prediction.\n",
    "\n",
    "Set the variables `TRAIN_GPU/TRAIN_NGPU` and `DEPLOY_GPU/DEPLOY_NGPU` to use a container image supporting a GPU and the number of GPUs allocated to the virtual machine (VM) instance. For example, to use a GPU container image with 4 Nvidia Telsa K80 GPUs allocated to each VM, you would specify:\n",
    "\n",
    "    (aip.AcceleratorType.NVIDIA_TESLA_K80, 4)\n",
    "\n",
    "\n",
    "Otherwise specify `(None, None)` to use a container image to run on a CPU.\n",
    "\n",
    "Learn more about [ hardware accelerator support for your region](https://cloud.google.com/vertex-ai/docs/general/locations#accelerators).\n",
    "\n",
    "*Note*: TF releases before 2.3 for GPU support will fail to load the custom model in this tutorial. It is a known issue and fixed in TF 2.3. This is caused by static graph ops that are generated in the serving function. If you encounter this issue on your own custom models, use a container image for TF 2.3 with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipG9uBUDRRRm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"IS_TESTING_TRAIN_GPU\"):\n",
    "    TRAIN_GPU, TRAIN_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_TRAIN_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    TRAIN_GPU, TRAIN_NGPU = (None, None)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_GPU\"):\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (\n",
    "        aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "        int(os.getenv(\"IS_TESTING_DEPLOY_GPU\")),\n",
    "    )\n",
    "else:\n",
    "    DEPLOY_GPU, DEPLOY_NGPU = (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "container:training,prediction"
   },
   "source": [
    "#### Set pre-built containers\n",
    "\n",
    "Set the pre-built Docker container image for training and prediction.\n",
    "\n",
    "\n",
    "For the latest list, see [Pre-built containers for training](https://cloud.google.com/ai-platform-unified/docs/training/pre-built-containers).\n",
    "\n",
    "\n",
    "For the latest list, see [Pre-built containers for prediction](https://cloud.google.com/ai-platform-unified/docs/predictions/pre-built-containers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrKTNnVLRRRm"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TF\"):\n",
    "    TF = os.getenv(\"IS_TESTING_TF\")\n",
    "else:\n",
    "    TF = \"2-1\"\n",
    "\n",
    "if TF[0] == \"2\":\n",
    "    if TRAIN_GPU:\n",
    "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf2-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf2-cpu.{}\".format(TF)\n",
    "else:\n",
    "    if TRAIN_GPU:\n",
    "        TRAIN_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        TRAIN_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "    if DEPLOY_GPU:\n",
    "        DEPLOY_VERSION = \"tf-gpu.{}\".format(TF)\n",
    "    else:\n",
    "        DEPLOY_VERSION = \"tf-cpu.{}\".format(TF)\n",
    "\n",
    "TRAIN_IMAGE = \"gcr.io/cloud-aiplatform/training/{}:latest\".format(TRAIN_VERSION)\n",
    "DEPLOY_IMAGE = \"gcr.io/cloud-aiplatform/prediction/{}:latest\".format(DEPLOY_VERSION)\n",
    "\n",
    "print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "print(\"Deployment:\", DEPLOY_IMAGE, DEPLOY_GPU, DEPLOY_NGPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "machine:training,prediction"
   },
   "source": [
    "#### Set machine type\n",
    "\n",
    "Next, set the machine type to use for training and prediction.\n",
    "\n",
    "- Set the variables `TRAIN_COMPUTE` and `DEPLOY_COMPUTE` to configure  the compute resources for the VMs you will use for for training and prediction.\n",
    " - `machine type`\n",
    "     - `n1-standard`: 3.75GB of memory per vCPU.\n",
    "     - `n1-highmem`: 6.5GB of memory per vCPU\n",
    "     - `n1-highcpu`: 0.9 GB of memory per vCPU\n",
    " - `vCPUs`: number of \\[2, 4, 8, 16, 32, 64, 96 \\]\n",
    "\n",
    "*Note: The following is not supported for training:*\n",
    "\n",
    " - `standard`: 2 vCPUs\n",
    " - `highcpu`: 2, 4 and 8 vCPUs\n",
    "\n",
    "*Note: You may also use n2 and e2 machine types for training and deployment, but they do not support GPUs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4RhNsDzRRRn"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"IS_TESTING_TRAIN_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_TRAIN_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "if os.getenv(\"IS_TESTING_DEPLOY_MACHINE\"):\n",
    "    MACHINE_TYPE = os.getenv(\"IS_TESTING_DEPLOY_MACHINE\")\n",
    "else:\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "VCPU = \"4\"\n",
    "DEPLOY_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "print(\"Deploy machine type\", DEPLOY_COMPUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tutorial_start:custom"
   },
   "source": [
    "# Tutorial\n",
    "\n",
    "Now you are ready to start creating your own custom model and training for CIFAR10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examine_training_package"
   },
   "source": [
    "### Examine the training package\n",
    "\n",
    "#### Package layout\n",
    "\n",
    "Before you start the training, you will look at how a Python package is assembled for a custom training job. When unarchived, the package contains the following directory/file layout.\n",
    "\n",
    "- PKG-INFO\n",
    "- README.md\n",
    "- setup.cfg\n",
    "- setup.py\n",
    "- trainer\n",
    "  - \\_\\_init\\_\\_.py\n",
    "  - task.py\n",
    "\n",
    "The files `setup.cfg` and `setup.py` are the instructions for installing the package into the operating environment of the Docker image.\n",
    "\n",
    "The file `trainer/task.py` is the Python script for executing the custom training job. *Note*, when we referred to it in the worker pool specification, we replace the directory slash with a dot (`trainer.task`) and dropped the file suffix (`.py`).\n",
    "\n",
    "#### Package Assembly\n",
    "\n",
    "In the following cells, you will assemble the training package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpA6MFcLRRRn"
   },
   "outputs": [],
   "source": [
    "# Make folder for Python training script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Add package information\n",
    "! touch custom/README.md\n",
    "\n",
    "setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n",
    "! echo \"$setup_cfg\" > custom/setup.cfg\n",
    "\n",
    "setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'tensorflow_datasets==1.3.0',\\n\\n    ],\\n\\n    packages=setuptools.find_packages())\"\n",
    "! echo \"$setup_py\" > custom/setup.py\n",
    "\n",
    "pkg_info = \"Metadata-Version: 1.0\\n\\nName: CIFAR10 image classification\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n",
    "! echo \"$pkg_info\" > custom/PKG-INFO\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86f3ab08b20a"
   },
   "source": [
    "### Create a custom component for training the custom model\n",
    "\n",
    "Next, create a lightweight Python function component for training the CIFAR10 image classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2etUCVVMRRRo"
   },
   "outputs": [],
   "source": [
    "# Single, Mirror and Multi-Machine Distributed Training for CIFAR-10\n",
    "\n",
    "@component(\n",
    "    base_image=\"tensorflow/tensorflow:latest\",\n",
    "    packages_to_install=[\"tensorflow_datasets\", \"opencv-python-headless\"],\n",
    ")\n",
    "def custom_train_model(\n",
    "    model_dir: str,\n",
    "    lr: float = 0.01,\n",
    "    epochs: int = 10,\n",
    "    steps: int = 200,\n",
    "    distribute: str = \"single\",\n",
    "):\n",
    "\n",
    "    import faulthandler\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "    from tensorflow.python.client import device_lib\n",
    "\n",
    "    faulthandler.enable()\n",
    "    tfds.disable_progress_bar()\n",
    "\n",
    "    print(\"Component start\")\n",
    "\n",
    "    print(\"Python Version = {}\".format(sys.version))\n",
    "    print(\"TensorFlow Version = {}\".format(tf.__version__))\n",
    "    print(\"TF_CONFIG = {}\".format(os.environ.get(\"TF_CONFIG\", \"Not found\")))\n",
    "    print(\"DEVICES\", device_lib.list_local_devices())\n",
    "\n",
    "    # Single Machine, single compute device\n",
    "    if distribute == \"single\":\n",
    "        if tf.test.is_gpu_available():\n",
    "            strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "        else:\n",
    "            strategy = tf.distribute.OneDeviceStrategy(device=\"/cpu:0\")\n",
    "    # Single Machine, multiple compute device\n",
    "    elif distribute == \"mirror\":\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "    # Multiple Machine, multiple compute device\n",
    "    elif distribute == \"multi\":\n",
    "        strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "    # Multi-worker configuration\n",
    "    print(\"num_replicas_in_sync = {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "    # Preparing dataset\n",
    "    BUFFER_SIZE = 10000\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    def make_datasets_unbatched():\n",
    "\n",
    "        # Scaling CIFAR10 data from (0, 255] to (0., 1.]\n",
    "        def scale(image, label):\n",
    "            image = tf.cast(image, tf.float32)\n",
    "            image /= 255.0\n",
    "            return image, label\n",
    "\n",
    "        datasets, info = tfds.load(name=\"cifar10\", with_info=True, as_supervised=True)\n",
    "        return datasets[\"train\"].map(scale).cache().shuffle(BUFFER_SIZE).repeat()\n",
    "\n",
    "    # Build the Keras model\n",
    "    def build_and_compile_cnn_model(lr: int = 0.01):\n",
    "        model = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    32, 3, activation=\"relu\", input_shape=(32, 32, 3)\n",
    "                ),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "                tf.keras.layers.MaxPooling2D(),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=lr),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # Train the model\n",
    "    NUM_WORKERS = strategy.num_replicas_in_sync\n",
    "    # Here the batch size scales up by number of workers since\n",
    "    # `tf.data.Dataset.batch` expects the global batch size.\n",
    "    GLOBAL_BATCH_SIZE = BATCH_SIZE * NUM_WORKERS\n",
    "    train_dataset = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
    "\n",
    "    with strategy.scope():\n",
    "        # Creation of dataset, and model building/compiling need to be within\n",
    "        # `strategy.scope()`.\n",
    "        model = build_and_compile_cnn_model(lr)\n",
    "\n",
    "    model.fit(x=train_dataset, epochs=epochs, steps_per_epoch=steps)\n",
    "    model.save(model_dir)\n",
    "\n",
    "    model_path_to_deploy = model_dir\n",
    "\n",
    "    # Load the saved model\n",
    "    local_model = tf.keras.models.load_model(model_dir)\n",
    "\n",
    "    # Load evaluation data\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "    (_, _), (x_test, y_test) = cifar10.load_data()\n",
    "    x_test = (x_test / 255.0).astype(np.float32)\n",
    "\n",
    "    print(x_test.shape, y_test.shape)\n",
    "\n",
    "    # Perform the model evaluation\n",
    "    local_model.evaluate(x_test, y_test)\n",
    "\n",
    "    # Serving function for image data\n",
    "    CONCRETE_INPUT = \"numpy_inputs\"\n",
    "\n",
    "    def _preprocess(bytes_input):\n",
    "        decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "        decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
    "        resized = tf.image.resize(decoded, size=(32, 32))\n",
    "        return resized\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "    def preprocess_fn(bytes_inputs):\n",
    "        decoded_images = tf.map_fn(\n",
    "            _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "        )\n",
    "        return {\n",
    "            CONCRETE_INPUT: decoded_images\n",
    "        }  # User needs to make sure the key matches model's input\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "    def serving_fn(bytes_inputs):\n",
    "        images = preprocess_fn(bytes_inputs)\n",
    "        prob = m_call(**images)\n",
    "        return prob\n",
    "\n",
    "    m_call = tf.function(local_model.call).get_concrete_function(\n",
    "        [tf.TensorSpec(shape=[None, 32, 32, 3], dtype=tf.float32, name=CONCRETE_INPUT)]\n",
    "    )\n",
    "\n",
    "    tf.saved_model.save(\n",
    "        local_model, model_path_to_deploy, signatures={\"serving_default\": serving_fn}\n",
    "    )\n",
    "\n",
    "    # Get the serving function signature\n",
    "    loaded = tf.saved_model.load(model_path_to_deploy)\n",
    "\n",
    "    serving_input = list(\n",
    "        loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    "    )[0]\n",
    "    print(\"Serving function input:\", serving_input)\n",
    "\n",
    "    # Get test items\n",
    "    test_image_1 = x_test[0]\n",
    "    test_image_2 = x_test[1]\n",
    "    print(test_image_1.shape)\n",
    "\n",
    "    BUCKET_URI = model_dir + \"/test\"\n",
    "\n",
    "    import cv2\n",
    "\n",
    "    cv2.imwrite(\"tmp1.jpg\", (test_image_1 * 255).astype(np.uint8))\n",
    "    cv2.imwrite(\"tmp2.jpg\", (test_image_2 * 255).astype(np.uint8))\n",
    "\n",
    "    print(\"Writing jpg files\")\n",
    "\n",
    "    # Copy test item(s)\n",
    "    # For the batch prediction, copy the test items over to your Cloud Storage bucket.\n",
    "    test_item_1 = BUCKET_URI + \"/tmp1.jpg\"\n",
    "    test_item_2 = BUCKET_URI + \"/tmp2.jpg\"\n",
    "\n",
    "    with tf.io.gfile.GFile(test_item_1, \"wb\") as w:\n",
    "        with tf.io.gfile.GFile(\"tmp1.jpg\", \"rb\") as r:\n",
    "            bytes = r.read()\n",
    "            w.write(bytes)\n",
    "\n",
    "    with tf.io.gfile.GFile(test_item_2, \"wb\") as w:\n",
    "        with tf.io.gfile.GFile(\"tmp2.jpg\", \"rb\") as r:\n",
    "            bytes = r.read()\n",
    "            w.write(bytes)\n",
    "\n",
    "    # Make the batch input file\n",
    "    import base64\n",
    "    import json\n",
    "\n",
    "    gcs_input_uri = BUCKET_URI + \"/\" + \"test.jsonl\"\n",
    "    with tf.io.gfile.GFile(gcs_input_uri, \"w\") as f:\n",
    "        bytes = tf.io.read_file(test_item_1)\n",
    "        b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "        data = {serving_input: {\"b64\": b64str}}\n",
    "        f.write(json.dumps(data) + \"\\n\")\n",
    "        bytes = tf.io.read_file(test_item_2)\n",
    "        b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")\n",
    "        data = {serving_input: {\"b64\": b64str}}\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1abdbe48"
   },
   "source": [
    "### Convert the component to a Vertex AI Custom Job\n",
    "\n",
    "Next, use the `create_custom_training_job_op_from_component` method to convert the custom component into a Vertex AI Custom Job pre-built component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deb6c1cc"
   },
   "outputs": [],
   "source": [
    "custom_job_distributed_training_op = utils.create_custom_training_job_op_from_component(\n",
    "    custom_train_model, replica_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e57e7311"
   },
   "source": [
    "### Define the pipeline for the custom training job\n",
    "\n",
    "Next, define the pipeline job, consisting of the tasks:\n",
    "\n",
    "- Train the custom model.\n",
    "- Upload the model to a Verex AI Model resource.\n",
    "- Execute a batch prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5R23d2J_HJr-"
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = BUCKET_URI + \"/model\"\n",
    "MODEL_DISPLAY_NAME = f\"train_deploy_{TIMESTAMP}\"\n",
    "ENDPOINT_NAME = \"pipelines-created-endpoint\"\n",
    "\n",
    "\n",
    "@dsl.pipeline(name=\"custom-model-training-sample-pipeline\")\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    model_display_name: str = MODEL_DISPLAY_NAME,\n",
    "    model_dir: str = MODEL_DIR,\n",
    "    lr: float = 0.01,\n",
    "    epochs: int = 10,\n",
    "    steps: int = 200,\n",
    "    distribute: str = \"single\",\n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from google_cloud_pipeline_components.v1.batch_predict_job import \\\n",
    "        ModelBatchPredictOp\n",
    "    from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "#    from google_cloud_pipeline_components import ModelUploadOp, EndpointCreateOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n",
    "                                                              ModelDeployOp)\n",
    "    from kfp.v2.components import importer_node\n",
    "\n",
    "    custom_producer_task = custom_job_distributed_training_op(\n",
    "        model_dir=model_dir,\n",
    "        lr=lr,\n",
    "        epochs=epochs,\n",
    "        steps=steps,\n",
    "        distribute=distribute,\n",
    "        project=PROJECT_ID,\n",
    "        location=REGION,\n",
    "        base_output_directory=PIPELINE_ROOT,\n",
    "    )\n",
    "\n",
    "    \n",
    "    unmanaged_model_importer = importer_node.importer(\n",
    "        artifact_uri=model_dir,\n",
    "        artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        metadata={\n",
    "            \"containerSpec\": {\n",
    "                \"imageUri\": \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-3:latest\"\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    \n",
    "\n",
    "    model_upload_op = ModelUploadOp(\n",
    "        project=PROJECT_ID,\n",
    "        display_name=\"model_display_name\",\n",
    "        unmanaged_container_model=unmanaged_model_importer.outputs[\"artifact\"],\n",
    "        #unmanaged_container_model=\"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-3:latest\",\n",
    "    )\n",
    "    model_upload_op.after(custom_producer_task)\n",
    "    \n",
    "    endpoint_create_op = EndpointCreateOp(\n",
    "        project=project,\n",
    "        display_name=ENDPOINT_NAME,\n",
    "        )\n",
    "\n",
    "    \n",
    "    model_deploy_op = ModelDeployOp(\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        model=model_upload_op.outputs[\"model\"],\n",
    "        deployed_model_display_name=model_display_name,\n",
    "        dedicated_resources_machine_type=\"n1-standard-16\",\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "        traffic_split = {\"0\": 100}\n",
    "    )\n",
    "\n",
    "    model_deploy_op.after(model_upload_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e584790f"
   },
   "source": [
    "### Compile and run the pipeline\n",
    "Next, you compile the pipeline into a DAG and then exeute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6be28881"
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"custom_model_training_spec.json\"\n",
    ")\n",
    "\n",
    "DISPLAY_NAME = \"cifar10_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"custom_model_training_spec.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    enable_caching=False\n",
    ")\n",
    "\n",
    "#job.run(service_account=SERVICE_ACCOUNT)\n",
    "\n",
    "job.run(sync=False\n",
    "       )\n",
    "\n",
    "! rm custom_model_training_spec.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow_datasets --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_ID = !(gcloud ai endpoints list --region=$REGION \\\n",
    "              --format='value(ENDPOINT_ID)' \\\n",
    "              --filter=display_name=$ENDPOINT_NAME \\\n",
    "              --sort-by=creationTimeStamp | tail -1)\n",
    "ENDPOINT_ID = ENDPOINT_ID[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample data \n",
    "!gsutil cp gs://bigquery-handson/vertexai_sample_data/ariplane-sample.jpeg ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "file_data = open(\"airplane-sample.jpeg\", \"rb\").read()\n",
    "b64_data = base64.b64encode(file_data).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = [{\"b64\" : b64_data}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def endpoint_predict(\n",
    "    project: str, location: str, instances: list, endpoint: str\n",
    "):\n",
    "    aip.init(project=project, location=location)\n",
    "\n",
    "    endpoint = aip.Endpoint(endpoint)\n",
    "\n",
    "    prediction = endpoint.predict(instances=instances)\n",
    "    return prediction\n",
    "\n",
    "result = endpoint_predict(PROJECT_ID, REGION, instance, ENDPOINT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_list[np.argmax(result.predictions)]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "custom_model_training_and_batch_prediction.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
